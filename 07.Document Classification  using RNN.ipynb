{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b2a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "data = tf.keras.utils.get_file(\"aclImdb_v1\",\n",
    "                             \"https://ai.stanford.edu/~amaas/data/sentiment/aclMndb_v1.tar.gz\",\n",
    "                             untar = True,cache_dir='.',cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(data),'aclImdb')\n",
    "train_dir = os.path.join(dataset_dir,'train')\n",
    "\n",
    "shutil.rmtree(os.path.join(train_dir,'unsup'))\n",
    "\n",
    "batch_size = 128\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\"aclImdb/train/\",\n",
    "                                                     validation_split=0.2,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     subset=\"training\",\n",
    "                                                     seed=seed)\n",
    "\n",
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\"aclImdb/train/\",\n",
    "                                                       validation_split=0.2,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       subset=\"validation\",\n",
    "                                                       seed=seed)\n",
    "\n",
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\"aclImdb/test/\",\n",
    "                                                        batch_size=batch_size,)\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = raw_val_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "test_ds = raw_test_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lower_case = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lower_case,'<br />',' ')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                   f'[{re.escape(string.punctuation)}]','')\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(standardize=custom_standardization,\n",
    "                                                    max_tokens=10000,\n",
    "                                                    output_mode='int',\n",
    "                                                    output_sequence_length=250)\n",
    "\n",
    "train_text = train_ds.map(lambda x,y : x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09ed1a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 341s 2s/step - loss: 0.4337 - accuracy: 0.7642 - val_loss: 0.3037 - val_accuracy: 0.8747\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 248s 2s/step - loss: 0.2220 - accuracy: 0.9126 - val_loss: 0.3940 - val_accuracy: 0.8646\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 255s 2s/step - loss: 0.1622 - accuracy: 0.9403 - val_loss: 0.3870 - val_accuracy: 0.8565\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 234s 1s/step - loss: 0.1298 - accuracy: 0.9503 - val_loss: 0.4688 - val_accuracy: 0.8542\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 245s 2s/step - loss: 0.0996 - accuracy: 0.9607 - val_loss: 0.5218 - val_accuracy: 0.8273\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 245s 2s/step - loss: 0.0673 - accuracy: 0.9757 - val_loss: 0.5564 - val_accuracy: 0.8583\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 245s 2s/step - loss: 0.0444 - accuracy: 0.9831 - val_loss: 0.5563 - val_accuracy: 0.8414\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 174s 1s/step - loss: 0.0367 - accuracy: 0.9866 - val_loss: 0.6492 - val_accuracy: 0.8349\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 177s 1s/step - loss: 0.0276 - accuracy: 0.9902 - val_loss: 0.8119 - val_accuracy: 0.8120\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 177s 1s/step - loss: 0.0298 - accuracy: 0.9895 - val_loss: 0.8034 - val_accuracy: 0.8492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1533432e170>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(input_dim=len(vectorize_layer.get_vocabulary()),output_dim=64,\n",
    "                              mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,validation_data=val_ds,epochs=10,validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "137be356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "[[ 1.1898861]\n",
      " [-1.249563 ]]\n",
      "[[1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "samples = np.array([\n",
    "    'The movie is good',\n",
    "    'The movie is not good'\n",
    "])\n",
    "\n",
    "pred = model.predict(samples)\n",
    "print(pred)\n",
    "print(np.where(pred > 0,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a685729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b2583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0d401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
